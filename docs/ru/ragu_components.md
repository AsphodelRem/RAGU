# RAGU

---
1. [Терминология](#терминология)
2. [Введение в методологию построения графа знаний](#введение-в-методологию-построения-графа-знаний)

   1. [Разбиение текста на чанки](#1-разбиение-текста-на-чанки)
   2. [Извлечение сущностей, отношений и описаний](#2-извлечение-сущностей-отношений-и-описаний)
   3. [Обработка триплетов](#3-обработка-триплетов)
   4. [Построение графа и выделение комьюнити](#4-построение-графа-и-выделение-комьюнити)

3. [RAG](#RAG)

   1. [Локальный поиск](#локальный-поиск)
   2. [Глобальный поиск](#глобальный-поиск)

4. [Компоненты RAGU](#компоненты-ragu)

   1. [Чанкеры](#чанкеры)
   2. [Пайплайн извлечения графа](#пайплайн-извлечения-графа)
   3. [Граф знаний](#граф-знаний)
   4. [Поиск по графу знаний](#поиск-по-графу-знаний)

---

## Терминология
1. **Чанк** - один из фрагментов текста, полученный при разбиении исходного корпуса на части.
2. **Разбиение на чанки** - процесс разделения текста на фрагменты (чанки).
3. **Сущность (узел/вершина)** - объект, выделенный из текста, имеющий самостоятельное значение (например, персона, организация, событие, место). В графе представляется как вершина.
4. **Отношение (ребро/связь)** - семантическая связь между двумя сущностями (например, *«Пётр I — правитель → Российская империя»*). В графе представляется как ребро между вершинами.
5. **Комьюнити** - подгруппа вершин в графе, которая имеет плотные внутренние связи, но относительно слабые связи с остальной частью графа (кластер/сообщество).
6. **Суммаризация** - процесс получения краткого и единого представления некоторого текста или множества описаний.
7. **Абстрактивный вопрос** - вопрос, для ответа на который требуется агрегировать и связать информацию из всего текстового корпуса или из большой его части (пример: «Какое мнение каждый спикер подкаста высказывал по поводу применения ИИ в медицине?»)
8. **Экстрактивный вопрос** - вопрос, на который можно ответить выбором или извлечением конкретного фрагмента из текста (пример: «В каком году родился Пётр I?»).

---

## Введение в методологию построения графа знаний

### 1. Разбиение текста на чанки

Для облегчения работы входной текстовый корпус разбивается на небольшие фрагменты.
Для разбиения предусмотрены разные стратегии:

* **`SimpleChunker`** - фиксированное разбиение по длине текста.
* **`SemanticChunker`** - разбиение с учётом семантической связи между предложениями.
* **`SmartChunker`** - ещё одно семантическое разбиение текста.

---

### 2. Извлечение сущностей, отношений и описаний

Для каждого фрагмента выполняется извлечение структурированной информации:

* **Сущности**: текстовое представление, тип сущности, описание сущности по контексту.
* **Отношения**: текстовое описание отношения между двумя сущностями (или просто класс отношения), сила этого отношения.

> **RAGU использует классы сущностей и отношений из [NEREL](https://github.com/nerel-ds/NEREL).**

Представленные классы сущностей:

|No. | Entity type | No. | Entity type | No. | Entity type
|---|---|---|---|---|---
|1. | AGE | 11. | FAMILY | 21. | PENALTY
|2. | AWARD | 12. | IDEOLOGY | 22. | PERCENT
|3. | CITY | 13. | LANGUAGE | 23. | PERSON
|4. | COUNTRY | 14. | LAW | 24. | PRODUCT
|5. | CRIME | 15. | LOCATION | 25. | PROFESSION
|6. | DATE | 16. | MONEY | 26. | RELIGION
|7. | DISEASE | 17. | NATIONALITY | 27. | STATE_OR_PROV
|8. | DISTRICT | 18. | NUMBER | 28. | TIME
|9. | EVENT | 19. | ORDINAL | 29. | WORK_OF_ART
|10. | FACILITY | 20. | ORGANIZATION |  |

Представленные классы отношений:

|No. | Relation type | No. | Relation type | No. | Relation type
|---|---|---|---|---|---
|1. | ABBREVIATION | 18. | HEADQUARTERED_IN | 35. | PLACE_RESIDES_IN
|2. | AGE_DIED_AT | 19. | IDEOLOGY_OF | 36. | POINT_IN_TIME
|3. | AGE_IS | 20. | INANIMATE_INVOLVED | 37. | PRICE_OF
|4. | AGENT | 21. | INCOME | 38. | PRODUCES
|5. | ALTERNATIVE_NAME | 22. | KNOWS | 39. | RELATIVE
|6. | AWARDED_WITH | 23. | LOCATED_IN | 40. | RELIGION_OF
|7. | CAUSE_OF_DEATH | 24. | MEDICAL_CONDITION | 41. | SCHOOLS_ATTENDED
|8. | CONVICTED_OF | 25. | MEMBER_OF | 42. | SIBLING
|9. | DATE_DEFUNCT_IN | 26. | ORGANIZES | 43. | SPOUSE
|10. | DATE_FOUNDED_IN | 27. | ORIGINS_FROM | 44. | START_TIME
|11. | DATE_OF_BIRTH | 28. | OWNER_OF | 45. | SUBEVENT_OF
|12. | DATE_OF_CREATION | 29. | PARENT_OF | 46. | SUBORDINATE_OF
|13. | DATE_OF_DEATH | 30. | PART_OF | 47. | TAKES_PLACE_IN
|14. | END_TIME | 31. | PARTICIPANT_IN | 48. | WORKPLACE
|15. | EXPENDITURE | 32. | PENALIZED_AS | 49. | WORKS_AS
|16. | FOUNDED_BY | 33. | PLACE_OF_BIRTH |  |
|17. | HAS_CAUSE | 34. | PLACE_OF_DEATH |  |


При использовании стандартного пайплайна для извлечения сущностей и отношений применяется 29 классов сущностей из NEREL, типы отношений не фиксируются.
Это поведение определяется инструкцией `artifacts_extractor_prompt`.
---
> В планах — добавление извлечения сущностей и отношений через небольшую дообученную LLM / через набор узкоспециализированных моделей для NER и RE.
> Оба подхода используют набор классов для сущностей и отношений из NEREL.
---

### 3. Обработка триплетов

Из-за разнородности текста и параллельного извлечения могут появляться дублирующиеся сущности и отношения.
Для получения однородного узла/отношения может быть использована суммаризация, проходящая следующим образом:

1. Все описания, относящиеся к одной сущности/связи, агрегируются.
2. Для получения единого консистентного описания агрегированные тексты прогоняются через LLM. Этот шаг опциональный.

Пример:

* Вход:
 *Пётр Первый* → "русский царь"
  * *Пётр Великий* → "реформатор"
* Агрегация и суммаризация
  * *Пётр I (Пётр Великий)* → "Император России, проводивший масштабные реформы"

За этот процесс отвечают классы:

**`EntitySummarizer`** — агрегирование и суммаризация описаний узлов,
**`RelationSummarizer`** — агрегирование и суммаризация связей.

> В планах — добавление выравнивания (слияния) сущностей по онтологии. Для этого используется двухэтапная стратегия, позволяющая объединять разные наименования одной сущности (например: *«Пётр Первый»*, *«Император Пётр I»*, *«Пётр Великий»*).
>
> Статья: [Chepurova A. et al., 2024](https://aclanthology.org/2024.textgraphs-1.5.pdf).

---

### 4. Построение графа и выделение комьюнити
После выделения сущностей и отношений и их обработки происходит объединение всей информации в граф.
С логической точки зрения он является направленным (имеется субъект и объект), но из-за особенностей дальнейшей обработки хранится он как ненаправленный.

Для возможности ответа на абстрактивные вопросы, следуя методологии GraphRAG, применяется выделение комьюнити в графе и получение саммари по этим комьюнити.
Для выделения комьюнити используется [алгоритм Лейдена](https://en.wikipedia.org/wiki/Leiden_algorithm).
этого используется двухэтапная стратегия:
Затем, для каждого комьюнити генерируется саммари - текстовый отчет, описывающий ключевую смысловую составляющую, объединяющую узлы в комьюнити.
Отчет имеет следующий вид:
```json
{
    "title": "<название_отчёта>",
    "summary": "<краткое_описание>",
    "rating": "<оценка_важности>",
    "rating_explanation": "<обоснование_оценки>",
    "findings": [
        {
            "summary": "<краткое описание вывода 1>",
            "explanation": "<развёрнутое объяснение вывода 1>"
        },
        {
            "summary": "<краткое описание вывода 2>",
            "explanation": "<развёрнутое объяснение вывода 2>"
        }
    ]
}
```

За генерацию комьюнити саммари отвечает инструкция `community_report`.

На этапе получения релевантной информации для ответа на запрос пользователя этот отчет переводится в текстовый вид. Набор таких отчетов идёт как часть контекста для LLM.

---

## RAG

### Локальный поиск
Этап локального поиска больше подходит для задачи "поиска иголки в стоге сена" - получения релевантной информации для ответа на экстрактивные вопросы, требующие небольшого ограниченного контекста.
Например, вопрос вида "когда умер Александр Второй?".

Этап локального поиска делится на:
1. Поиск наиболее релевантных сущностей для запроса.
2. Получение всех релевантных отношений и соседних сущностей.
3. Поиск релевантных комьюнити саммари.
4. Поиск чанков, из которых вся релевантная информация была выделена.

Релевантность сущностей определяется близостью эмбеддинга запроса к эмбеддингу описания сущности.


После получения всего контекста из графа, формируется его единое представление в текстовом виде. Выглядит оно следующим образом:
```markdown
**Сущности**
Сущность, тип сущности, описание сущности
...

**Отношения**
Сущность-источник, целевая сущность, описание отношения, ранг отношения
...

**Саммари**
...

**Тексты**
...
```

После получения релевантной информации, контекст и запрос подаются в LLM и итоговый ответ возвращается пользователю.
За получение ответа на запрос отвечает инструкция `local_search`

---

### Глобальный поиск
Глобальный поиск делится на три этапа:
1. Получение релевантных комьюнити для ответа.
2. Получение мета ответов на запрос по каждому полученному комьюнити. На этом этапе каждому ответу соответствует некоторая оценка релевантности (от 0 до 10).
3. Все мета ответы (оценка релевантности > 0) сортируются по релевантности, а затем подаются как мета контекст вместе с запросов в LLM.

Мета ответы выглядят следующим образом:
```json
{
    "reasoning": "<твои рассуждения о релевантности контекста>",
    "response": "<твой ответ>",
    "rating": "<оценка релевантности контекста для ответа на запрос>"
}
```

За получение мета ответов отвечает инструкция `global_search_context`,
за получение итогового ответа — `global_search`.

Стоит отметить, что глобальный поиск - довольно дорогая операция :)

---

## Компоненты RAGU

### Чанкеры
Первый шаг для построения графа знаний - разбить входной корпус сырых текстов на чанки. 
RAGU реализует различные подходы к разбиению, а так же поддерживает добавление своих реализаций чанкинга.

За интерфейс чанкера отвечает класс BaseChunker (ragu/chunker/base_chunker)

Семантический чанкер представлен реализацией SmartChunker.

Детали можете найти здесь: 
https://github.com/bond005/smart_chunker/tree/main

---

### Пайплайн извлечения графа
В RAGU реализуется два варианта извлечения графа знаний из сырых текстов: классический, на базе LLM, и подход на основании небольших специализированных моделей на базе [RAGU-lm](https://huggingface.co/RaguTeam/RAGU-lm).
#### LLMArtifactExtractor

LLMArtifactExtractor - реализация классического варианта извлечения сущностей и отношений из GraphRAG, использующий LLM.


Пример использования:
```python
from ragu.triplet import ArtifactsExtractorLLM

...

pipeline = ArtifactsExtractorLLM(
    client=client,      # LLM клиент из ragu.llm
    do_validation=True  # Можем поставить валидацию выделенных артефактов
)
```

За выделение/валидацию элементов графа отвечают инструкции `artifact_extraction` и `artifact_validation`.

#### RAGU-lm

Для этого пайплайна используется дообученная под задачи выделения структурированной информации - [RAGU-lm](https://huggingface.co/RaguTeam/RAGU-lm)

Задачи, на которые обучена модель:
1. Распознавание ненормализованных именованных сущностей из текста.
2. Нормализация каждой из ненормализованных сущностей относительно текста.
3. Генерация определения каждой из нормализованных именованных сущностей относительно текста.
4. Генерации определения направленного отношения между парой нормализованных именованных сущностей относительно текста.

**System prompt**:
```
Вы - эксперт в области анализа текстов и извлечения семантической информации из них.
```

**Entity extraction**:
```
Распознайте все именованные сущности в тексте и выпишите их список с новой строки.\n\nТекст: {input_text}\n\nИменованные сущности:
```

<details>
<summary>Example</summary>

**Input**:
Распознайте все именованные сущности в тексте и выпишите их список с новой строки.

Текст: Семья Обамы приобрела дом в Вашингтоне за 8,1 млн долларов Барак Обама Бывший президент США Барак Обама с женой Мишель приобрели жильё в Вашингтоне недалеко от Белого дома. После окончания срока работы на посту президента в январе супруги арендовали особняк в стиле эпохи Тюдоров в престижном районе столицы США — Калорама, где долгое время селились дипломаты, лоббисты и политики. Младшей дочери Барака и Мишель — Саше осталось ещё два года до окончания частной школы в Вашингтоне. Поэтому семья решила выкупить дом с восемью спальными комнатами стоимостью 8,1 миллиона долларов. Ранее дом принадлежал бывшему пресс-секретарю экс-президента США Билла Клинтона Джо Локхарту (), который в настоящее время возглавляет пресс-службу Национальной футбольной лиги США. Среди соседей Обамы — видные деятели Вашингтона, включая дочь действующего президента Иванку Трамп и её мужа Джареда Кушнера (оба являются советниками Белого дома), которые переехали в район Калорама из Нью-Йорка в начале 2017 года. Госсекретарь США Рекс Тиллерсон тоже живёт в доме неподалеку. «Учитывая, что президент и миссис Обама планируют жить в Вашингтоне как минимум ещё два года, для них имело смысл приобрести дом в собственность, а не продолжать его арендовать», — сообщил представитель Обамы. Семья президента Обамы также владеет домом в Чикаго — третьем по величине городе в США, где Обама приобрёл значительную политическую поддержку перед тем, как дважды стал главою Белого дома.

Именованные сущности: 

**Expected output**:

Семья Обамы
Обамы
приобрела дом
Вашингтоне
8,1 млн долларов
Барак Обама
Обама
президент США
президент
США
Мишель
приобрели жильё
Белого дома
президента
в январе
Тюдоров
столицы США
Калорама
дипломаты
лоббисты
политики
Барака
Саше
два года
восемью
8,1 миллиона долларов
пресс-секретарю экс-президента США
пресс-секретарю
президента США
Билла Клинтона
Джо Локхарту
пресс-службу Национальной футбольной лиги США
Национальной футбольной лиги США
Вашингтона
Иванку Трамп
Джареда Кушнера
советниками Белого дома
Нью-Йорка
в начале 2017 года
Госсекретарь США
Госсекретарь
Рекс Тиллерсон
миссис Обама
представитель Обамы
Семья президента Обамы
Чикаго
третьем
главою Белого дома
</details>


**Normalization**:
```
Выполните нормализацию именованной сущности, встретившейся в тексте.\n\nИсходная (ненормализованная) именованная сущность: {source_entity}\n\nТекст: {source_text}\n\nНормализованная именованная сущность:
```

<details>
<summary>Example</summary>

**Input**:
Выполните нормализацию именованной сущности, встретившейся в тексте.

Исходная (ненормализованная) именованная сущность: пресс-секретарю

Текст: Семья Обамы приобрела дом в Вашингтоне за 8,1 млн долларов Барак Обама Бывший президент США Барак Обама с женой Мишель приобрели жильё в Вашингтоне недалеко от Белого дома. После окончания срока работы на посту президента в январе супруги арендовали особняк в стиле эпохи Тюдоров в престижном районе столицы США — Калорама, где долгое время селились дипломаты, лоббисты и политики. Младшей дочери Барака и Мишель — Саше осталось ещё два года до окончания частной школы в Вашингтоне. Поэтому семья решила выкупить дом с восемью спальными комнатами стоимостью 8,1 миллиона долларов. Ранее дом принадлежал бывшему пресс-секретарю экс-президента США Билла Клинтона Джо Локхарту (), который в настоящее время возглавляет пресс-службу Национальной футбольной лиги США. Среди соседей Обамы — видные деятели Вашингтона, включая дочь действующего президента Иванку Трамп и её мужа Джареда Кушнера (оба являются советниками Белого дома), которые переехали в район Калорама из Нью-Йорка в начале 2017 года. Госсекретарь США Рекс Тиллерсон тоже живёт в доме неподалеку. «Учитывая, что президент и миссис Обама планируют жить в Вашингтоне как минимум ещё два года, для них имело смысл приобрести дом в собственность, а не продолжать его арендовать», — сообщил представитель Обамы. Семья президента Обамы также владеет домом в Чикаго — третьем по величине городе в США, где Обама приобрёл значительную политическую поддержку перед тем, как дважды стал главою Белого дома.

Нормализованная именованная сущность: 

**Expected output**:

пресс-секретарь
</details>

**Entity description generation**:

```
Напишите, что означает именованная сущность в тексте, то есть раскройте её смысл относительно текста.\n\nИменованная сущность: {normalized_entity}\n\nТекст: {source_text}\n\nСмысл именованной сущности:
```

<details>
<summary>Example</summary>

**Input**:
Напишите, что означает именованная сущность в тексте, то есть раскройте её смысл относительно текста.

Именованная сущность: пресс-секретарь

Текст: Семья Обамы приобрела дом в Вашингтоне за 8,1 млн долларов Барак Обама Бывший президент США Барак Обама с женой Мишель приобрели жильё в Вашингтоне недалеко от Белого дома. После окончания срока работы на посту президента в январе супруги арендовали особняк в стиле эпохи Тюдоров в престижном районе столицы США — Калорама, где долгое время селились дипломаты, лоббисты и политики. Младшей дочери Барака и Мишель — Саше осталось ещё два года до окончания частной школы в Вашингтоне. Поэтому семья решила выкупить дом с восемью спальными комнатами стоимостью 8,1 миллиона долларов. Ранее дом принадлежал бывшему пресс-секретарю экс-президента США Билла Клинтона Джо Локхарту (), который в настоящее время возглавляет пресс-службу Национальной футбольной лиги США. Среди соседей Обамы — видные деятели Вашингтона, включая дочь действующего президента Иванку Трамп и её мужа Джареда Кушнера (оба являются советниками Белого дома), которые переехали в район Калорама из Нью-Йорка в начале 2017 года. Госсекретарь США Рекс Тиллерсон тоже живёт в доме неподалеку. «Учитывая, что президент и миссис Обама планируют жить в Вашингтоне как минимум ещё два года, для них имело смысл приобрести дом в собственность, а не продолжать его арендовать», — сообщил представитель Обамы. Семья президента Обамы также владеет домом в Чикаго — третьем по величине городе в США, где Обама приобрёл значительную политическую поддержку перед тем, как дважды стал главою Белого дома.

Смысл именованной сущности: 

**Expected output**:

Бывший представитель СМИ экс-президента США Билла Клинтона.
</details>

**Relation extraction**:

```
Напишите, что означает отношение между двумя именованными сущностями в тексте, то есть раскройте смысл этого отношения относительно текста (либо напишите прочерк, если между двумя именованными сущностями отсутствует отношение).\n\nПервая именованная сущность: {first_normalized_entity}\n\nВторая именованная сущность: {second_normalized_entity}\n\nТекст: {source_text}\n\nСмысл отношения между двумя именованными сущностями:
```

<details>
<summary>Example</summary>

**Input:**
Напишите, что означает отношение между двумя именованными сущностями в тексте, то есть раскройте смысл этого отношения относительно текста (либо напишите прочерк, если между двумя именованными сущностями отсутствует отношение).

Первая именованная сущность: Джо Локхарт

Вторая именованная сущность: пресс-служба Национальной футбольной лиги США

Текст: Семья Обамы приобрела дом в Вашингтоне за 8,1 млн долларов Барак Обама Бывший президент США Барак Обама с женой Мишель приобрели жильё в Вашингтоне недалеко от Белого дома. После окончания срока работы на посту президента в январе супруги арендовали особняк в стиле эпохи Тюдоров в престижном районе столицы США — Калорама, где долгое время селились дипломаты, лоббисты и политики. Младшей дочери Барака и Мишель — Саше осталось ещё два года до окончания частной школы в Вашингтоне. Поэтому семья решила выкупить дом с восемью спальными комнатами стоимостью 8,1 миллиона долларов. Ранее дом принадлежал бывшему пресс-секретарю экс-президента США Билла Клинтона Джо Локхарту (), который в настоящее время возглавляет пресс-службу Национальной футбольной лиги США. Среди соседей Обамы — видные деятели Вашингтона, включая дочь действующего президента Иванку Трамп и её мужа Джареда Кушнера (оба являются советниками Белого дома), которые переехали в район Калорама из Нью-Йорка в начале 2017 года. Госсекретарь США Рекс Тиллерсон тоже живёт в доме неподалеку. «Учитывая, что президент и миссис Обама планируют жить в Вашингтоне как минимум ещё два года, для них имело смысл приобрести дом в собственность, а не продолжать его арендовать», — сообщил представитель Обамы. Семья президента Обамы также владеет домом в Чикаго — третьем по величине городе в США, где Обама приобрёл значительную политическую поддержку перед тем, как дважды стал главою Белого дома.

Смысл отношения между двумя именованными сущностями: 

**Expected output:**
Возглавляет пресс-службу Национальной футбольной лиги США.
</details>


**Как использовать:**

Чтобы запустить инференс Ragu-lm, рекомендуется установить vllm.
https://docs.vllm.ai/en/latest/

Первый шаг - запустить vllm.
```bash
sudo vllm serve RaguTeam/ragu-lm --max_model_len 4096 
```

Инициализируем класс RaguLmArtifactExtractor и дальше можем обращаться к модели в коде.
```python
from ragu.triplet.ragu_lm_artifact_extractor import RaguLmArtifactExtractor

...

pipeline = RaguLmArtifactExtractor(
    ragu_lm_vllm_url="http://0.0.0.0:8000/v1/",     
)

entities, relations = pipeline(["some_texts"])
```

---


### Граф знаний
Для эффективного поиска релевантной информации производится индексация всех элементов графа знаний и их сохранение.

За хранение и доступ к элементам графа знаний отвечает класс KnowledgeGraph.

```python
# Первое - настроенный пайплайн для построения графа
pipeline = InMemoryGraphBuilder(
    client,
    chunker,
    artifact_extractor,
    embedder=embedder,
    use_clustering=True,
    cluster_only_if_more_than=2
)

# Второе - настроенное хранилище графа знаний
index = Index(
    embedder,
    graph_storage_kwargs={"clustering_params": {"max_cluster_size": 6}}
)
```

```python
knowledge_graph = KnowledgeGraph(
    extraction_pipeline=pipeline,   
    index=index,
    make_community_summary=True,    
    language="russian",
)
```

Для каждой сущности создаётся эмбеддинг (векторное представление) её описания, который затем сохраняется в векторной базе данных. На данный момент используется `nano-db`.
Остальные данные хранятся в виде json.

---


### Поиск по графу знаний


#### Local search
Локальный поиск - это что-то вроде гранулированного векторного RAG. Сначала ищем top-k релевантных сущностей из графа. Затем для каждоый сущности:
1. Берем все соседние сущности 
2. Берем все отношения, в которых они участвуют, 
3. Берем комьюнити, в который сущность состоит
4. Берем чанки, из которых эти сущности были выделены.

Все это подается как структурированный контекст для ответа на запрос пользователя.

Пример использования:
```python
from ragu.search_engine import LocalSearchEngine

...

search_engine = LocalSearchEngine(
    client,                 # LLM 
    knowledge_graph,        # Граф знаний
    embedder                # Эмбеддер для векторизации запроса
) 

# Поиск релевантного контекста в графе
search_result = await search_engine.a_search("Кто написал роман 'Камо Грядеши'?")

# Получение ответа по графу знаний 
response = await search_engine.a_query("Кто написал роман 'Камо Грядеши'?") 
```


#### Global Search
Глобальный поиск - поиск по комьюнити в графе.

Алгоритм:
1. Берем каждое комьюнити из графа.
2. Получаем ответ на запрос по каждому комьюнити саммари.
Каждый ответ содержит так же оценку его полезности для итогового ответа на запрос (от 0 до 10).
3. Получаем итоговый ответ на запрос, взяв в качестве контекста ответы с предыдущего этапа, отсортированные по релевантности.

```python
from ragu.search_engine import GlobalSearchEngine

...

search_engine = GlobalSearchEngine(
    client, 
    knowledge_graph
)

# Поиск релевантного контекста в графе
search_result = await search_engine.a_search("Кто написал роман 'Камо Грядеши'?")

# Получение ответа по графу знаний 
response = await search_engine.a_query("Кто написал роман 'Камо Грядеши'?") 
```

---

### Prompt tuning

У каждого класса, который использует LLM под капотом, можно поменять используемую инструкцию.

Сейчас все инструкции представлены классом `PromptTemplate`.
```python
@dataclass
class PromptTemplate:
    """
    Represents a Jinja2-based prompt template for instruction generation.

    Each template defines:
      - a Jinja2 text pattern (`template`)
      - an optional Pydantic schema for structured output validation (`schema`)
      - a short description of its purpose (`description`)

    The template can be rendered dynamically with keyword arguments,
    supporting both single-instance and batched (list/tuple) generation.
    """

    template: str                       #  jinja2 шаблон инструкции.
    schema: Type[BaseModel] = None      # pydantic модель для структурированного ответа.
    description: str = ""               # краткое описание инструкции.

...
```

Получение словаря вида `"название_инструкции" : "соответствующий_prompt_template"`:
```python
search_engine = LocalSearchEngine(
    client,
    knowledge_graph,
    embedder
)

print(search_engine.get_prompts())

# {'local_search': PromptTemplate(template='\n**Goal**\nAnswer the query by summarizing relevant information from the context and, if necessary, well-known facts.\n\n**Instructions**\n1. If you do not know the correct answer, explicitly state that.\n2. Do not include unsupported information.\n\nQuery: {{ query }}\nContext: {{ context }}\n\nProvide the answer in the following language: {{ language }}\nReturn the result as valid JSON matching the provided schema.\n', schema=<class 'ragu.common.prompts.default_models.DefaultResponseModel'>, description='Prompt for generating a local context-based search response.')}
```

Обновление инструкции:
```python
search_engine.update_prompt("local_search", PromptTemplate(template="Новая инструкция в виде jinja2 шаблона", schema=SomeSchemaOfNeeded, description="Описание вашей инструкции (можно оставить пустой)"))
```


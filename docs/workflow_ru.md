## Терминология
1. **Чанк** - один из фрагментов текста, полученный при разбиении исходного корпуса на части.
2. **Разбиение на чанки** - процесс разделения текста на фрагменты (чанки).
3. **Сущность (узел/вершина)** - объект, выделенный из текста, имеющий самостоятельное значение (например, персона, организация, событие, место). В графе представляется как вершина.
4. **Отношение (ребро/связь)** - семантическая связь между двумя сущностями (например, *«Пётр I — правитель → Российская империя»*). В графе представляется как ребро между вершинами.
5. **Комьюнити** - подгруппа вершин в графе, которая имеет плотные внутренние связи, но относительно слабые связи с остальной частью графа (кластер/сообщество).
6. **Суммаризация** - процесс получения краткого и единого представления некоторого текста или множества описаний.
7. **Абстрактивный вопрос** - вопрос, для ответа на который требуется агрегировать и связать информацию из всего текстового корпуса или из большой его части (пример: «Какое мнение каждый спикер подкаста высказывал по поводу применения ИИ в медицине?»)
8. **Экстрактивный вопрос** - вопрос, на который можно ответить выбором или извлечением конкретного фрагмента из текста (пример: «В каком году родился Пётр I?»).

---

## Построение графа знаний

### 1. Разбиение текста на чанки

Для облегчения работы входной текстовый корпус разбивается на небольшие фрагменты.
Для разбиения предусмотрены разные стратегии:

* **`SimpleChunker`** - фиксированное разбиение по длине текста.
* **`SemanticChunker`** - разбиение с учётом семантической связи между предложениями.
* **`SmartChunker`** - ещё одно семантическое разбиение текста.

---

### 2. Извлечение сущностей, отношений и описаний

Для каждого фрагмента выполняется извлечение структурированной информации:

* **Сущности**: текстовое представление, тип сущности, описание сущности по контексту.
* **Отношения**: текстовое описание отношения между двумя сущностями (или просто класс отношения), сила этого отношения.

> **RAGU использует классы сущностей и отношений из [NEREL](https://github.com/nerel-ds/NEREL).**

Представленные классы сущностей:

|No. | Entity type | No. | Entity type | No. | Entity type
|---|---|---|---|---|---
|1. | AGE | 11. | FAMILY | 21. | PENALTY
|2. | AWARD | 12. | IDEOLOGY | 22. | PERCENT
|3. | CITY | 13. | LANGUAGE | 23. | PERSON
|4. | COUNTRY | 14. | LAW | 24. | PRODUCT
|5. | CRIME | 15. | LOCATION | 25. | PROFESSION
|6. | DATE | 16. | MONEY | 26. | RELIGION
|7. | DISEASE | 17. | NATIONALITY | 27. | STATE_OR_PROV
|8. | DISTRICT | 18. | NUMBER | 28. | TIME
|9. | EVENT | 19. | ORDINAL | 29. | WORK_OF_ART
|10. | FACILITY | 20. | ORGANIZATION |  |

Представленные классы отношений:

|No. | Relation type | No. | Relation type | No. | Relation type
|---|---|---|---|---|---
|1. | ABBREVIATION | 18. | HEADQUARTERED_IN | 35. | PLACE_RESIDES_IN
|2. | AGE_DIED_AT | 19. | IDEOLOGY_OF | 36. | POINT_IN_TIME
|3. | AGE_IS | 20. | INANIMATE_INVOLVED | 37. | PRICE_OF
|4. | AGENT | 21. | INCOME | 38. | PRODUCES
|5. | ALTERNATIVE_NAME | 22. | KNOWS | 39. | RELATIVE
|6. | AWARDED_WITH | 23. | LOCATED_IN | 40. | RELIGION_OF
|7. | CAUSE_OF_DEATH | 24. | MEDICAL_CONDITION | 41. | SCHOOLS_ATTENDED
|8. | CONVICTED_OF | 25. | MEMBER_OF | 42. | SIBLING
|9. | DATE_DEFUNCT_IN | 26. | ORGANIZES | 43. | SPOUSE
|10. | DATE_FOUNDED_IN | 27. | ORIGINS_FROM | 44. | START_TIME
|11. | DATE_OF_BIRTH | 28. | OWNER_OF | 45. | SUBEVENT_OF
|12. | DATE_OF_CREATION | 29. | PARENT_OF | 46. | SUBORDINATE_OF
|13. | DATE_OF_DEATH | 30. | PART_OF | 47. | TAKES_PLACE_IN
|14. | END_TIME | 31. | PARTICIPANT_IN | 48. | WORKPLACE
|15. | EXPENDITURE | 32. | PENALIZED_AS | 49. | WORKS_AS
|16. | FOUNDED_BY | 33. | PLACE_OF_BIRTH |  |
|17. | HAS_CAUSE | 34. | PLACE_OF_DEATH |  |


При использовании стандартного пайплайна для извлечения сущностей и отношений применяется 29 классов сущностей из NEREL, типы отношений не фиксируются.
Это поведение определяется инструкцией `artifacts_extractor_prompt`.
---
> В планах — добавление извлечения сущностей и отношений через небольшую дообученную LLM / через набор узкоспециализированных моделей для NER и RE.
> Оба подхода используют набор классов для сущностей и отношений из NEREL.
---

### 3. Обработка триплетов

Из-за разнородности текста и параллельного извлечения могут появляться дублирующиеся сущности и отношения.
Для получения однородного узла/отношения может быть использована суммаризация, проходящая следующим образом:

1. Все описания, относящиеся к одной сущности/связи, агрегируются.
2. Для получения единого консистентного описания агрегированные тексты прогоняются через LLM. Этот шаг опциональный.

Пример:

* Вход:
 *Пётр Первый* → "русский царь"
  * *Пётр Великий* → "реформатор"
* Агрегация и суммаризация
  * *Пётр I (Пётр Великий)* → "Император России, проводивший масштабные реформы"

За этот процесс отвечают классы:

**`EntitySummarizer`** — агрегирование и суммаризация описаний узлов,
**`RelationSummarizer`** — агрегирование и суммаризация связей.

> В планах — добавление выраванивания (слияния) сущностей по оэтого используется двухэтапная стратегия:нтологии, позволяющего объединять разные наименования одной сущности (например: *«Пётр Первый»*, *«Император Пётр I»*, *«Пётр Великий»*).
>
> Статья: [Chepurova A. et al., 2024](https://aclanthology.org/2024.textgraphs-1.5.pdf).

---

### 4. Построение графа и выделение комьюнити
После выделения сущностей и отношений и их обработки происходит объединение всей информации в граф.
С логической точки зрения он является направленным (имеется субъект и объект), но из-за особенностей дальнейшей обработки хранится он как ненаправленный.

Для возможности ответа на абстрактивные вопросы, следуя методологии GraphRAG, применяется выделение комьюнити в графе и получение саммари по этим комьюнити.
Для выделения комьюнити используется [алгоритм Лейдена](https://en.wikipedia.org/wiki/Leiden_algorithm).
этого используется двухэтапная стратегия:
Затем, для каждого комьюнити генерируется саммари - текстовый отчет, описывающий ключевую смысловую составляющую, объединяющую узлы в комьюнити.
Отчет имеет следующий вид:
```json
{
    "title": "<название_отчёта>",
    "summary": "<краткое_описание>",
    "rating": "<оценка_важности>",
    "rating_explanation": "<обоснование_оценки>",
    "findings": [
        {
            "summary": "<краткое описание вывода 1>",
            "explanation": "<развёрнутое объяснение вывода 1>"
        },
        {
            "summary": "<краткое описание вывода 2>",
            "explanation": "<развёрнутое объяснение вывода 2>"
        }
    ]
}
```

За генерацию комьюнити саммари отвечет инструкция `community_summary_prompt`.

На этапе получения релевантной информации для ответа на запрос пользователя этот отчет переводится в текстовый вид. Набор таких отчетов идёт как часть контекста для LLM.

---

### 5. Индексация
Для эффективного поиска релевантной информации производится индексация всех элементов графа знаний и их сохранение.

Для каждой сущности создаётся эмбеддинг её описания, который затем сохраняется в векторной базе данных. На данный момент используется `nano-db`.
Остальные данные хранятся в виде json.

---

## Этап поиска информации и получение ответа на запрос по контексту из графа знаний используется двухэтапная стратегия:

### Локальный поиск
Этап локального поиска больше подходит для задачи "поиска иголки в стоге сена" - получения релевантной информации для ответа на экстрактивные вопросы, требующие небольшого ограниченного контекста.
Например, вопрос вида "когда умер Александр Второй?".

Этап локального поиска делится на:
1. Поиск наиболее релевантных сущностей для запроса.
2. Получение всех релевантных отношений и соседних сущностей.
3. Поиск релевантных комьюнити саммари.
4. Поиск чанков, из которых вся релевантная информация была выделена.

Релевантность сущностей определяется близостью эмбеддинга запроса к эмбеддингу описания сущности.


После получения всего контекста из графа, формируется его единое представление в текстовом виде. Выглядит оно следующим образом:
```markdown
**Сущности**
Сущность, тип сущности, описание сущности
...

**Отношения**
Сущность-источник, целевая сущность, описание отношения, ранг отношения
...

**Саммари**
...

**Тексты**
...
```

После получения релевантной информации, контекст и запрос подаются в LLM и итоговый ответ возвращается пользователю.
За получение ответа на запрос отвечает инструкция `local_search_engine_prompt`

---

### Глобальный поиск
Глобальный поиск делится на три этапа:
1. Получение релевантных комьюнити для ответа.
2. Получение мета ответов на запрос по каждому полученному комьюнити. На этом этапе каждому ответу соответствует некоторая оценка релевантности (от 0 до 10).
3. Все мета ответы (оценка релевантности > 0) сортируются по релевантности, а затем подаются как мета контекст вместе с запросов в LLM.

Мета ответы выглядят следующим образом:
```json
{
    "reasoning": "<твои рассуждения о релевантности контекста>",
    "response": "<твой ответ>",
    "rating": "<оценка релевантности контекста для ответа на запрос>"
}
```

За получение мета ответов отвечает инструкция `global_search_metadata_collection_prompt`,
за получение итогового ответа — `global_search_engine_prompt`.

Стоит отметить, что глобальный поиск - довольно дорогая операция :)

---

## TODO 📝
1. Добавление выравнивания по онтологиям.
2. Добавление дополнительных пайплайнов для извлечения сущностей и отношений.
3. Добавление учёта темпоральности в графе знаний.
